{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV1NGnqZ4rTk"
   },
   "source": [
    "# **NLP Research Project** - Training the BERTopic Model\n",
    "## Description\n",
    "- This program uses the csv file generated by pushShift.py to train a BERTopic model for the purpose of generating a topic model.\n",
    "\n",
    "Author: Joseph A. Tomasello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas bertopic nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to connect to the Kean University GPU server\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsQqu1fe4pTj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # Load the dataset from the CSV file\n",
    "    df = pd.read_csv('dataset_all_posts_4years_sorted.csv', usecols=['datetime', 'selftext'])\n",
    "    # Drop unwanted rows directly\n",
    "    df = df[~df['selftext'].isin(['[deleted]', '[removed]'])]\n",
    "    # Handling missing values\n",
    "    df.dropna(subset=['selftext'], inplace=True)\n",
    "\n",
    "    # Preprocessing\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "\n",
    "    subset_df = df[(df['datetime'] >= \"2021-03-12 00:00:00\") & (df['datetime'] < \"2022-03-12 00:00:00\")]\n",
    "\n",
    "    text = subset_df['selftext']\n",
    "    docs = list(text)\n",
    "\n",
    "    print(\"Number of documents:\", len(docs))\n",
    "\n",
    "    # Check for missing values or outliers\n",
    "    print(\"Number of missing values:\", df['selftext'].isnull().sum())\n",
    "    print(\"Max length of a document:\", df['selftext'].str.len().max())\n",
    "\n",
    "    # Debugging print to check document lengths before and after truncation\n",
    "    print(\"Document lengths after truncation:\")\n",
    "    print(df['selftext'].apply(len).describe())\n",
    "\n",
    "    # Check for NaN values\n",
    "    print(\"Number of NaN values:\", df['selftext'].isna().sum())\n",
    "\n",
    "    try:\n",
    "        # Check for infinite values\n",
    "        print(\"Number of infinite values:\", np.isinf(df['selftext']).sum())\n",
    "    except TypeError:\n",
    "        print(\"Unable to check for infinite values due to data type mismatch.\")\n",
    "\n",
    "    timestamps = pd.to_datetime(subset_df['datetime']).dt.to_period('m')\n",
    "    timestamps = [str(x) for x in timestamps]\n",
    "    timestamps = list(timestamps)\n",
    "    timestamps.sort()\n",
    "    docs = [str(x) for x in docs]\n",
    "\n",
    "    # Set the model and parameters\n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 3), stop_words=\"english\")\n",
    "\n",
    "    # Initialize SentenceTransformer model\n",
    "    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Use DataParallel for multiple GPUs\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "        sentence_model = torch.nn.DataParallel(sentence_model)\n",
    "\n",
    "    # Move model to GPU\n",
    "    sentence_model = sentence_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize BERTopic with SentenceTransformer model\n",
    "    model = BERTopic(\n",
    "        embedding_model=sentence_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        language='english',\n",
    "        calculate_probabilities=True\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    topics, probs = model.fit_transform(docs)\n",
    "\n",
    "    # Save the model\n",
    "    with open(f'bertopic_model_2021.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Print topic information\n",
    "    print(model.get_topic_info())\n",
    "    freq = model.get_topic_info()\n",
    "    freq.head(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
