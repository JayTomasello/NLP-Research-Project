{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV1NGnqZ4rTk"
   },
   "source": [
    "# **NLP Research Project** - BERTopic Time Series Visualizations\n",
    "## Description\n",
    "- This program uses the csv file generated by pushShift.py + a trained BERTopic model to extract the major topics at monthly intervals from a 1-year subset of the dataset. The results are then visualized over that 1-year span using a line graph.\n",
    "\n",
    "Author: Joseph A. Tomasello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas bertopic nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to connect to the Kean University GPU server\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsQqu1fe4pTj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.plotting._hierarchical_documents import visualize_hierarchical_documents\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "def main():\n",
    "    # Load the dataset from the CSV file\n",
    "    df = pd.read_csv('dataset_all_posts_4years_sorted.csv', usecols=['datetime', 'selftext'])\n",
    "    df = df[~df['selftext'].isin(['[deleted]', '[removed]'])]  # Drop unwanted rows directly\n",
    "    # Handling missing values\n",
    "    df.dropna(subset=['selftext'], inplace=True)\n",
    "\n",
    "    # Preprocessing\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    # print(df['datetime'])\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "\n",
    "    subset_df = df[(df['datetime'] >= \"2020-03-12 00:00:00\") & (df['datetime'] < \"2021-03-12 00:00:00\")]\n",
    "\n",
    "    text = subset_df['selftext']\n",
    "    docs = list(text)\n",
    "\n",
    "    timestamps = pd.to_datetime(subset_df['datetime']).dt.to_period('m')\n",
    "    timestamps = [str(x) for x in timestamps]\n",
    "    timestamps = list(timestamps)\n",
    "    timestamps.sort()\n",
    "    print(\"# of Timestamps:\", len(timestamps))\n",
    "    docs = [str(x) for x in docs]\n",
    "\n",
    "    filename = \"bertopic_model_2020.pkl\"\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    # Visualize topics over time\n",
    "    topics_over_time = model.topics_over_time(docs, timestamps, nr_bins=20)\n",
    "    model.visualize_topics_over_time(topics_over_time).show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
