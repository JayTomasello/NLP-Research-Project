"""
pushshiftDFSetupSA.py

This program modifies the dataframe generated by pushshift.py for the purposes 
of performing a sentiment analysis using libraries such as TextBlob, VADER, 
and NRC Lexicon.

Author: Joseph A. Tomasello 
"""


"""
BEGIN - SCRIPT PREPARATION
"""
import pandas as pd
import re
"""
END - SCRIPT PREPARATION 
"""


"""
BEGIN - FUNCTIONS
"""
# This function uses the csv dataset file passed to it to create a dataframe and prep
# the selftext column (the post's body text) for analysis use
def create_dataframe(dataset_filename, analysis_column):

    # Creates a dataframe using a dataset file
    dataframe = pd.read_csv(dataset_filename, encoding="utf8")
    
    # Filters out any collected posts that were removed by the subreddit's moderators
    dataframe = dataframe[dataframe.selftext != "[removed]"]
    # Filters out any collected posts that were deleted by the post's author
    dataframe = dataframe[dataframe.selftext != "[deleted]"]
    
    # Adds a new column to the dataframe to store a cleaned version (stripped of special 
    # characters and non-relevant text) of the selftext for each collected post
    dataframe['clean_body_text'] = dataframe[analysis_column].apply( lambda x: clean_text_SA( str(x) ) )

    return dataframe

# This helper function removes all special characters and text not relevant to performing a
# sentiment analysis (i.e., special characters and URLs)
def clean_text_SA(text):
    
    text = text.replace('\n', ' ')                 # Removes any newline characters
    text = text.replace('\r\r', ' ')               # Removes any carriage return characters
    text = re.sub(r'http\S+', '', text)            # Removes any URLs beginning with http
    text = re.sub(r'www\S+', '', text)             # Removes any URLs beginning with www
    text_clean = text.replace('&amp;#x200B;', ' ') # Removes any zero-width space characters
    
    return text_clean

# This function filters posts out of the dataframe collected from a particular subreddit
def subreddit_filter(dataframe, subreddit_column, subreddit_name):

    # Filters out any collected posts from the subreddit specifed by the user
    filtered_dataframe = dataframe[ dataframe[subreddit_column] != subreddit_name ]

    return filtered_dataframe

# This function converts and saves the dataframe passed to it as a csv file
def save_dataframe_as_csv(dataframe, file_name):

    # Converts and saves the dataframe to a csv file
    dataframe.to_csv(file_name, index=False)
"""
END - FUNCTIONS
"""
